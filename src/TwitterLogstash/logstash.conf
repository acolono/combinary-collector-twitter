# tutorial/blog : https://www.elastic.co/blog/logstash-jdbc-input-plugin
#   plugin docs : https://www.elastic.co/guide/en/logstash/current/plugins-inputs-jdbc.html
#        source : https://github.com/logstash-plugins/logstash-input-jdbc
input {
    jdbc {
        jdbc_driver_library => "/postgresql.driver.jar"
        jdbc_driver_class => "org.postgresql.Driver"
        jdbc_connection_string => "jdbc:postgresql://db:5432/postgres"
        jdbc_user => "postgres"
        jdbc_password => ""
        schedule => "* * * * *" # every minute
        jdbc_paging_enabled => true
        jdbc_page_size => "${JDBC_PAGE_SIZE:50000}"
        statement => '
			SELECT
			  m.id,
			  t.id as tweet_id,
			  t.is_retweet,
			  u.screen_name,
			  u.profile_image_url,
			  t.text,
			  t.hashtags,
			  concat_ws($$,$$, t.lat, t.lon) as location,
			  t.country,
			  t.country_code,
			  t.place,
			  t.deleted,
			  m.favourites_count,
			  m.retweet_count,
			  m.ts

			FROM db.metric m
			LEFT JOIN db.tweet t on m.tweet_id = t.id
			LEFT JOIN db."user" u on t.user_id = u.id
            WHERE m.id > :sql_last_value
            ORDER BY m.id ASC
        '
        use_column_value => true
        tracking_column_type => "numeric"
        tracking_column => id
    }
}
output {
    # stdout { codec => json_lines } # just for debugging
    elasticsearch {
        index => "twitter"
        # document_type => "flat" # deprecated
        document_id => "%{tweet_id}" # primary key (lowercase!) - upserts
        hosts => "${ELASTICSEARCH_HOST:http://elasticsearch:9200/}"
    }
}
